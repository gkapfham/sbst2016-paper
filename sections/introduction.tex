% vim: ft=tex
%!TEX root=sbst2016.tex

\section{Introduction}
\label{sec:introduction}

The field of search-based software testing (SBST) often involves the implementation and experimental evaluation of
algorithms that employ randomization. For instance, automated test data generation (ATDG) with the alternating variable
method, or \AVM, employs randomness when it restarts after not finding data that successfully meets the chosen
testing objectives~\cite{McMinn2015}. Or, a genetic algorithm performing automated test suite prioritisation (ATSP) that
reorders tests during regression testing will randomly mutate portions of a candidate test suite in order to
create the best ordering~\cite{Walcott2006}.

Scientists must carefully design and conduct the experiments evaluating these algorithms to ensure that they account for
any inherent randomness. It is additionally important that these scientists employ the right methods to analyse the results
from these experiments. In the year 2011, Arcuri and Briand published a conference paper outlining some practical
guidelines for using statistical methods to analyse randomized algorithms~\cite{Arcuri2011}, like those often used in
SBST. The journal version of this paper, entitled ``A Hitchhiker's Guide to Statistical Tests for
Assessing Randomized Algorithms in Software Engineering''~\cite{Arcuri2014}, expands on the earlier paper while still
providing practical ways to rigorously analysis empirical results.


